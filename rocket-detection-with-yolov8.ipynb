{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8343066,"sourceType":"datasetVersion","datasetId":4955294}],"dockerImageVersionId":30698,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Rocket Detection with YOLOv8 üöÄüîç\n\n## Introduction üåü\n\nWelcome to the \"Rocket Detection Project\" using YOLOv8. This project is dedicated to detecting rockets in images using the YOLO (You Only Look Once) object detection framework with the latest YOLOv8 architecture. Rockets, with their distinctive shapes and features, present a unique challenge for object detection, making this project both exciting and technically challenging. By leveraging state-of-the-art deep learning techniques, we aim to accurately detect and localize rockets within images, contributing to advancements in aerial object recognition and surveillance.\n\n## Project Goals üéØ\n\n- Implement the YOLOv8 architecture for rocket detection.\n- Train the YOLOv8 model using a dataset of 640 train and 640 validation images collected from open image sources.\n- Optimize the model for accurate and efficient rocket detection.\n- Evaluate the model's performance on a separate test set and analyze its detection capabilities.\n- Visualize the detected rockets and showcase the model's accuracy.\n\n## Dataset Overview üìä\n\nThe rocket detection dataset comprises a diverse set of images containing rockets in various environments and contexts. The dataset is collected from open image sources and includes images with different rocket sizes, orientations, and backgrounds. This rich dataset provides ample training and validation data for our YOLOv8 model to learn and generalize effectively.\n\nSee more detailed overview about dataset : https://www.kaggle.com/datasets/eneskosar19/rocket-dataset-for-image-detection-labelled\n\n## Data Preprocessing üõ†Ô∏è\n\n- Preprocessing the dataset to ensure uniformity and quality in the images.\n- Annotating the images with bounding boxes to indicate the presence and location of rockets.\n- Preparing the data pipeline for efficient training and validation of the YOLOv8 model.\n\n## YOLOv8 Model ü§ñ\n\nWe will deploy the YOLOv8 architecture, which is a state-of-the-art object detection model known for its speed and accuracy. The YOLOv8 model consists of a deep neural network with multiple layers, including convolutional layers, pooling layers, and detection layers, designed to detect objects with high precision and speed in real-time scenarios.\n\n## Model Training and Evaluation üöÄ\n\n- Training the YOLOv8 model using the annotated dataset and optimizing it for rocket detection.\n- Evaluating the model's performance on a separate test set using metrics such as mean average precision (mAP) and intersection over union (IoU).\n- Fine-tuning the model and exploring hyperparameter adjustments to enhance detection accuracy and reduce false positives.\n\n## Visualizing the Model Outputs üìà\n\n- Visualizing the detections made by the YOLOv8 model on sample images.\n- Analyzing the model's performance in detecting rockets of different sizes, orientations, and backgrounds.\n- Discussing the model's strengths, limitations, and potential areas for further improvement.\n\n## Conclusion üåü\n\nIn conclusion, the Rocket Detection Project using YOLOv8 demonstrates the capabilities of advanced object detection techniques in identifying and localizing rockets within images. By leveraging the YOLOv8 architecture and a carefully curated dataset, we aim to achieve accurate and efficient rocket detection for applications in aerial surveillance, space exploration, and defense systems. This project not only showcases the technical prowess of modern deep learning frameworks but also opens avenues for future research and development in object detection technologies.\n","metadata":{}},{"cell_type":"markdown","source":"# 1. INSTALLATIONS AND IMPORTINGS","metadata":{}},{"cell_type":"code","source":"!nvidia-smi","metadata":{"id":"eODSI2i-eGR4","execution":{"iopub.status.busy":"2024-05-07T07:03:38.245437Z","iopub.execute_input":"2024-05-07T07:03:38.245715Z","iopub.status.idle":"2024-05-07T07:03:39.322631Z","shell.execute_reply.started":"2024-05-07T07:03:38.245686Z","shell.execute_reply":"2024-05-07T07:03:39.321632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will use YOLO from ultralytics see detailed source : https://docs.ultralytics.com/","metadata":{}},{"cell_type":"code","source":"%pip install ultralytics\nimport ultralytics\nultralytics.checks()\n","metadata":{"id":"fa87d19e-fd94-4f59-90e3-49d89c061e16","executionInfo":{"status":"aborted","timestamp":1715027130629,"user_tz":-180,"elapsed":4,"user":{"displayName":"Enes Ko≈üar","userId":"07792689668025404027"}},"execution":{"iopub.status.busy":"2024-05-07T07:03:43.057769Z","iopub.execute_input":"2024-05-07T07:03:43.058527Z","iopub.status.idle":"2024-05-07T07:04:09.106615Z","shell.execute_reply.started":"2024-05-07T07:03:43.058475Z","shell.execute_reply":"2024-05-07T07:04:09.105564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from ultralytics import YOLO\nimport os","metadata":{"id":"W_MbIR52eko6","executionInfo":{"status":"ok","timestamp":1715027193509,"user_tz":-180,"elapsed":325,"user":{"displayName":"Enes Ko≈üar","userId":"07792689668025404027"}},"execution":{"iopub.status.busy":"2024-05-07T07:04:09.108609Z","iopub.execute_input":"2024-05-07T07:04:09.109493Z","iopub.status.idle":"2024-05-07T07:04:09.113487Z","shell.execute_reply.started":"2024-05-07T07:04:09.109451Z","shell.execute_reply":"2024-05-07T07:04:09.112623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. LOAD PRETRAINED YOLO MODEL","metadata":{}},{"cell_type":"code","source":"root_dir = \"/kaggle/input/Dataset/Dataset\"","metadata":{"id":"EVps0RHDedXF","executionInfo":{"status":"ok","timestamp":1715027195896,"user_tz":-180,"elapsed":410,"user":{"displayName":"Enes Ko≈üar","userId":"07792689668025404027"}},"execution":{"iopub.status.busy":"2024-05-07T07:04:09.114956Z","iopub.execute_input":"2024-05-07T07:04:09.115323Z","iopub.status.idle":"2024-05-07T07:04:09.130269Z","shell.execute_reply.started":"2024-05-07T07:04:09.115297Z","shell.execute_reply":"2024-05-07T07:04:09.129589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls /kaggle/input/Dataset/Dataset","metadata":{"execution":{"iopub.status.busy":"2024-05-07T07:04:09.132264Z","iopub.execute_input":"2024-05-07T07:04:09.132529Z","iopub.status.idle":"2024-05-07T07:04:10.11249Z","shell.execute_reply.started":"2024-05-07T07:04:09.132506Z","shell.execute_reply":"2024-05-07T07:04:10.111282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = YOLO(\"yolov8n.yaml\")","metadata":{"id":"8077700c-7f0d-4654-91d8-0b77fa2b70f3","executionInfo":{"status":"ok","timestamp":1715027196972,"user_tz":-180,"elapsed":1,"user":{"displayName":"Enes Ko≈üar","userId":"07792689668025404027"}},"execution":{"iopub.status.busy":"2024-05-07T07:04:10.114035Z","iopub.execute_input":"2024-05-07T07:04:10.114422Z","iopub.status.idle":"2024-05-07T07:04:10.681587Z","shell.execute_reply.started":"2024-05-07T07:04:10.114389Z","shell.execute_reply":"2024-05-07T07:04:10.68075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. CREATE YAML FILE","metadata":{}},{"cell_type":"code","source":"# Create .yaml file \nimport yaml\n\ndata_yaml = dict(\n    train = '/kaggle/input/Dataset/Dataset/train',\n    val = '/kaggle/input/Dataset/Dataset/train',\n    nc = 1,\n    names = ['Rocket']\n)\n\n# Note that I am creating the file in the yolov5/data/ directory.\nwith open('data.yaml', 'w') as outfile:\n    yaml.dump(data_yaml, outfile, default_flow_style=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-07T07:04:13.869629Z","iopub.execute_input":"2024-05-07T07:04:13.869998Z","iopub.status.idle":"2024-05-07T07:04:13.877051Z","shell.execute_reply.started":"2024-05-07T07:04:13.869969Z","shell.execute_reply":"2024-05-07T07:04:13.876219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. TRAINING PROCESS","metadata":{}},{"cell_type":"code","source":"results = model.train(data=\"data.yaml\",epochs=250)","metadata":{"id":"A07gumoVeyrv","executionInfo":{"status":"ok","timestamp":1715030216207,"user_tz":-180,"elapsed":3012838,"user":{"displayName":"Enes Ko≈üar","userId":"07792689668025404027"}},"outputId":"b4b88eaf-b04b-4d76-95bb-e62ef9c462cc","execution":{"iopub.status.busy":"2024-05-07T07:04:19.115484Z","iopub.execute_input":"2024-05-07T07:04:19.116253Z","iopub.status.idle":"2024-05-07T08:20:18.709181Z","shell.execute_reply.started":"2024-05-07T07:04:19.116216Z","shell.execute_reply":"2024-05-07T08:20:18.708006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. PREDICTION PROCESS","metadata":{}},{"cell_type":"code","source":"!ls /kaggle/input/Dataset/Dataset/test/Rocket","metadata":{"execution":{"iopub.status.busy":"2024-05-07T08:21:54.847369Z","iopub.execute_input":"2024-05-07T08:21:54.848098Z","iopub.status.idle":"2024-05-07T08:21:55.880462Z","shell.execute_reply.started":"2024-05-07T08:21:54.848059Z","shell.execute_reply":"2024-05-07T08:21:55.879454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n!yolo task=detect mode=predict model=/kaggle/working/runs/detect/train/weights/best.pt conf=0.25 source=/kaggle/input/Dataset/Dataset/test/Rocket","metadata":{"execution":{"iopub.status.busy":"2024-05-07T08:21:39.198118Z","iopub.execute_input":"2024-05-07T08:21:39.198544Z","iopub.status.idle":"2024-05-07T08:21:50.416866Z","shell.execute_reply.started":"2024-05-07T08:21:39.198506Z","shell.execute_reply":"2024-05-07T08:21:50.415853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. RESULTS","metadata":{}},{"cell_type":"code","source":"!ls /kaggle/working/runs/detect/train/","metadata":{"execution":{"iopub.status.busy":"2024-05-07T08:22:33.888643Z","iopub.execute_input":"2024-05-07T08:22:33.889003Z","iopub.status.idle":"2024-05-07T08:22:34.892622Z","shell.execute_reply.started":"2024-05-07T08:22:33.888976Z","shell.execute_reply":"2024-05-07T08:22:34.891392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import display, Image\n\nImage(filename=f'/kaggle/working/runs/detect/train/confusion_matrix.png', width=900)","metadata":{"execution":{"iopub.status.busy":"2024-05-07T08:23:25.219596Z","iopub.execute_input":"2024-05-07T08:23:25.220268Z","iopub.status.idle":"2024-05-07T08:23:25.228598Z","shell.execute_reply.started":"2024-05-07T08:23:25.220231Z","shell.execute_reply":"2024-05-07T08:23:25.227579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Image(filename=f'/kaggle/working/runs/detect/train/results.png', width=900)","metadata":{"execution":{"iopub.status.busy":"2024-05-07T08:23:50.080536Z","iopub.execute_input":"2024-05-07T08:23:50.080909Z","iopub.status.idle":"2024-05-07T08:23:50.093441Z","shell.execute_reply.started":"2024-05-07T08:23:50.080879Z","shell.execute_reply":"2024-05-07T08:23:50.092418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ls runs/detect/predict","metadata":{"execution":{"iopub.status.busy":"2024-05-07T08:27:02.050797Z","iopub.execute_input":"2024-05-07T08:27:02.051174Z","iopub.status.idle":"2024-05-07T08:27:03.060016Z","shell.execute_reply.started":"2024-05-07T08:27:02.051144Z","shell.execute_reply":"2024-05-07T08:27:03.058778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7. PREDICTED IMAGES","metadata":{}},{"cell_type":"code","source":"Image(filename=f'runs/detect/predict/360_F_272511766_sI572Qc9PrDowwVQKu8UXTxVk1aEdccM.jpg', width=900)","metadata":{"execution":{"iopub.status.busy":"2024-05-07T08:27:21.09785Z","iopub.execute_input":"2024-05-07T08:27:21.098256Z","iopub.status.idle":"2024-05-07T08:27:21.107033Z","shell.execute_reply.started":"2024-05-07T08:27:21.098226Z","shell.execute_reply":"2024-05-07T08:27:21.106073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Image(filename=f'runs/detect/predict/image.jpg', width=900)","metadata":{"execution":{"iopub.status.busy":"2024-05-07T08:27:40.113582Z","iopub.execute_input":"2024-05-07T08:27:40.113952Z","iopub.status.idle":"2024-05-07T08:27:40.127176Z","shell.execute_reply.started":"2024-05-07T08:27:40.113925Z","shell.execute_reply":"2024-05-07T08:27:40.126114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Image(filename=f'runs/detect/predict/images.jpg', width=900)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-07T08:28:41.345858Z","iopub.execute_input":"2024-05-07T08:28:41.346459Z","iopub.status.idle":"2024-05-07T08:28:41.354321Z","shell.execute_reply.started":"2024-05-07T08:28:41.346425Z","shell.execute_reply":"2024-05-07T08:28:41.353257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CONCLUSION","metadata":{}},{"cell_type":"markdown","source":"In evaluating the model's performance metrics, we observed that the Mean Average Precision (mAP) at 50 score threshold was higher than mAP at 50-95 score thresholds.\n\nThis indicates that the model may not be as sensitive in detecting rockets in the mid-range confidence scores. Further analysis and fine-tuning may be required to improve the model's sensitivity across different confidence levels.\n\nRemember that we have only limited images to train.I strongly recommend you to find huge datasets if you want to work on something has accurate results. Despite that, we have managed to get 0.899 MAP50 score and 0.615 MAP50-95 score. \n\n## RECOMMENDATION ABOUT YOLOV8,IMAGE DETECTION\n\n1. Results in first 50 epoch is really poor, so let the model learn and train-itself.\n2. Choose your dataset carefully and check twice, if you use misslabeled or oversized-box labels, this cause mistraining and low scores.\n3. I strongly recommend you to **NOT** to work on Google Colab Free Version, because runtime dies suddenly and google drive dies too so you can't save nor see anything.\n4. Determine your dataset before train the model,it may require too much time in huge datasets. You can check my dataset size and related runtime.\n5. **Do not** work on CPU, you can use tensorflow-gpu(Your Physical Device), or Kaggle or some other platform's GPUS AND TPUS.\n","metadata":{}}]}